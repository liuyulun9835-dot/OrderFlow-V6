# V6历史工程日志记录
> 合并来源:
 - output/publish_docs/CHANGELOG.md
 - output/publish_docs/工程一致性与进度审计报告.md
 - docs/工程日志_order_flow_v​_6_(_2025_10_18_).md
 - docs/工程日志_order_flow_v​_6_（_2025_10_15_）.md
 - docs/工程日志_order_flow_v​_6_（_2025_10_17_).md
 - docs/工程日志_order_flow_v​_6_（_2025_10_23_）.md
 - docs/工程日志_order_flow_v​_6_（_2025_10_24_).MD

---

## 目录
- [源文件：output/publish_docs/CHANGELOG.md](#源文件outputpublishdocsCHANGELOGmd)
- [源文件：output/publish_docs/工程一致性与进度审计报告.md](#源文件outputpublishdocs工程一致性与进度审计报告md)
- [源文件：docs/工程日志_order_flow_v​_6_(_2025_10_18_).md](#源文件docs工程日志orderflowv​620251018md)
- [源文件：docs/工程日志_order_flow_v​_6_（_2025_10_15_）.md](#源文件docs工程日志orderflowv​620251015md)
- [源文件：docs/工程日志_order_flow_v​_6_（_2025_10_17_).md](#源文件docs工程日志orderflowv​620251017md)
- [源文件：docs/工程日志_order_flow_v​_6_（_2025_10_23_）.md](#源文件docs工程日志orderflowv​620251023md)
- [源文件：docs/工程日志_order_flow_v​_6_（_2025_10_24_).MD](#源文件docs工程日志orderflowv​620251024MD)

---

## 源文件：output/publish_docs/CHANGELOG.md

---
schema_version: v6.1
build_id: pending
data_manifest_hash: pending
calibration_hash: pending
---

# Placeholder

This document will be populated during the publish pipeline.

- schema_version: v6.1
- build_id: pending
- data_manifest_hash: pending
- calibration_hash: pending

---

## 源文件：output/publish_docs/工程一致性与进度审计报告.md

# OrderFlow V6 工程一致性与进度审计（修订 2.0 对照）

## 1. 结论
- 规范一致性：见 §2（BLOCKER/ WARN/ NIT 列表）。
- 安全与漏洞：见 §3（Bandit / pip‑audit / Secrets）。
- 分层工程化进度：见 §4（每层百分比与“已做/未做”）。

## 2. 规范一致性（对照《项目说明书_修订_2》/ README / todo）
- 数据来自 `/tmp/revision2_audit.json`：

```json
{  "violations": [    {      "id": "legacy_three_state",      "files": [        "OrderFlow V6 策略诊断与改进报告.txt",        "OrderFlow V6项目说明书_修订_2.md",        "README.md",        "tools/extract_spec.py"      ]    }  ],  "warnings": [],  "notes": []}
```

> 注：`legacy_three_state` 表示旧“三态”引用残留；`missing_*` 为与修订 2.0 不一致处。

## 3. 安全与漏洞

* Bandit：`/tmp/bandit.json`（若存在高危则标记 BLOCKER）。
* 依赖漏洞：`/tmp/pip_audit.json`（必须给出可用的修复版本或抑制理由）。
* 秘钥扫描：`/tmp/secrets.json`。

## 4. 分层工程化进度与注释

* 评分 JSON：`output/results/audit_progress.json`

```json
{  "governance": {    "progress_pct": 100.0,    "done": [      "schema_model",      "schema_decision",      "rules_transition"    ],    "missing": []  },  "data": {    "progress_pct": 0.0,    "done": [],    "missing": [      "manifests",      "ingestion"    ]  },  "features": {    "progress_pct": 50.0,    "done": [      "macro_factor"    ],    "missing": [      "microflow"    ]  },  "model": {    "progress_pct": 66.7,    "done": [      "train_tvtp",      "state_inference"    ],    "missing": [      "artifact"    ]  },  "decision": {    "progress_pct": 100.0,    "done": [      "directional",      "rules_examples"    ],    "missing": []  },  "execution": {    "progress_pct": 100.0,    "done": [      "switch_policy"    ],    "missing": []  },  "validation": {    "progress_pct": 100.0,    "done": [      "univariate",      "multivariate",      "validator_cfg"    ],    "missing": []  },  "output": {    "progress_pct": 100.0,    "done": [      "validation_md"    ],    "missing": []  },  "docs": {    "progress_pct": 100.0,    "done": [      "readme",      "todo"    ],    "missing": []  }}
```

### 4.1 逐层备注

* **governance**：进度 100.0% 
  * 已完成：schema_model, schema_decision, rules_transition
  * 缺失：无
* **data**：进度 0.0% 
  * 已完成：无
  * 缺失：manifests, ingestion
* **features**：进度 50.0% 
  * 已完成：macro_factor
  * 缺失：microflow
* **model**：进度 66.7% 
  * 已完成：train_tvtp, state_inference
  * 缺失：artifact
* **decision**：进度 100.0% 
  * 已完成：directional, rules_examples
  * 缺失：无
* **execution**：进度 100.0% 
  * 已完成：switch_policy
  * 缺失：无
* **validation**：进度 100.0% 
  * 已完成：univariate, multivariate, validator_cfg
  * 缺失：无
* **output**：进度 100.0% 
  * 已完成：validation_md
  * 缺失：无
* **docs**：进度 100.0% 
  * 已完成：readme, todo
  * 缺失：无

## 5. 建议的修复顺序（只列顺序与要点，具体补丁另附）

1. 治理契约：补齐 `SCHEMA_model/decision` 与 `RULES_library` 的 transition 触发；
2. 模型接口：最小可运行的 `train_tvtp.py` 与 `state_inference.py`；
3. 决策：`directional_classifier.py` 与规则示例；
4. 特征：`features/macro_factor/*`；
5. Validator：方向性分层与 TVTP 宏观对比产出；
6. 发布门控：CI 校验“契约已填充 + 方向性报告存在”。

---

## 源文件：docs/工程日志_order_flow_v​_6_(_2025_10_18_).md

# **工程日志 — OrderFlow V6（2025-10-18）**

> 日期：2025‑10‑18\
> 基准文档：`OrderFlow V6项目说明书_修订_2.md` / `README.md` / `order_flow_v​_6_todo.md`\
> 评估口径：不仅看“文件是否存在”，更关注**功能可用性、与上游/下游的耦合程度、可测试性与产物可追溯性**。

---

## 0. 结论快照（TL;DR）

- **总体功能完工度（加权）**：**58%**
- **核心短板**：`data/` 基座与 `features/microflow/` 未完，使得模型/验证只能处于**占位或半功能**状态。
- **优先顺序建议**：
  1. **先补 Data & Microflow 基建（最高优先级）**；
  2. 完成 TVTP‑HMM 真训练与制品落地（而非占位）；
  3. 训练化 `directional_classifier` + 概率校准，并接入规则/执行日志；
  4. 将 Validator 报告产出流水化，接入发布门禁（CI）。

---

## 1. 分层功能性评估（按修订 2.0 架构）

> 评分刻度：0 未启动 / 1 占位（能 import，不能用）/ 2 半功能（toy 可跑）/ 3 可用（端到端可跑，缺监控）/ 4 稳定可发布（含测试、指标、回滚）。

### 1.1 治理层（governance/\*）— **等级：3/4（完成度 75%）**

- **现状**：`SCHEMA_model.json`、`SCHEMA_decision.json`、`RULES_library.yaml` 已补齐关键字段与 `transition(...)` 触发。
- **缺口**：
  - Schema 校验脚本/CI gate **尚未实际绑定**到 PR（需要 actions 或 make 任务中添加 schema 校验步骤）。
  - `CONTROL_switch_policy.yaml` 在 release 校验条款里需强制检查近 7/30 天 `switch_audit`。
- **建议**：
  - 增加 `tools/validate_schema.py` + GH Actions 步骤；
  - 在 `output/report/release.yml` 中新增 **硬门禁**：缺 `VALIDATION.md` 的方向分层摘要 → 直接 fail。

### 1.2 数据层（data/\*）— **等级：0/4（完成度 0%）**

- **现状**：未见 `data/ingestion/` 与 `data/manifests/`；无水位与哈希清单。
- **风险**：所有下游（微观特征、TVTP 驱动、验证）均无法形成**可追溯**的训练/评估集。
- **建议（必做）**：
  - 建 `ingestion/`：`binance_ohlcv.py`（2017‑now, 1m）与 `atas_tick_to_1m.py`（近窗聚合）；
  - 建 `manifests/`：`manifest.jsonl` 写入 {source, sym, start, end, rows, file\_hash}；
  - 建 `watermark/`：记录最晚可用时间戳与拉取策略。

### 1.3 特征层（features/\*）— **等级：1.5/4（完成度 38%）**

- **现状**：
  - `features/macro_factor/macro_factor.py` 已有（MA200\_ratio 占位）；
  - `features/microflow/` 未落地（MFI/CVD/Imbalance 等缺实现与单测）。
- **建议（必做）**：
  - 建指标库：`mfi.py`、`cvd.py`、`imbalance.py`、`vpin.py(可后置)`；
  - 统一特征签名（列名/频率/对齐规则），产出 `featureset.parquet`；
  - 单测：对齐边界条件（缺失/跳时/零成交）。

### 1.4 模型层（model/hmm\_tvtp\_hsmm/\*）— **等级：1.5/4（完成度 38%）**

- **现状**：
  - `train_tvtp.py` 与 `state_inference.py` 存在，但**训练为占位逻辑**，`state_inference` 依赖手工 `score`；
  - 未见 `artifacts/` 持久化产物（四键签名、驱动列表、AIC/BIC 等）。
- **技术缺口**：
  - **TVTP 训练算法**（EM with logistic transitions）未实现；
  - **前向‑后向**推断需支持**时变转移矩阵**；
  - 多起点稳健化与交叉验证缺失。
- **建议（必做）**：
  - 先以**简化版**实现：
    1. 观测为高斯 / t 分布（任选），
    2. 转移 `P(S_t|S_{t-1}, X_t)` 用 **Logit(β·X)**；
    3. EM：E 步（FB with TVTP）、M 步（β 用 IRLS/牛顿法）
  - 产出 `artifacts/model_artifact.json`：states/tvtp/drivers/macro\_factor\_used/四键签名/AIC/BIC/多起点散点。

### 1.5 决策层（decision/\*）— **等级：2/4（完成度 50%）**

- **现状**：
  - `directional_classifier.py` 有占位打分；
  - `rules/transition_examples.yaml` 在位；
  - 与推断输出/执行日志的**耦合未打通**。
- **建议**：
  - 将 `predict_proba()` 与 `infer()` 合流为 `decision/engine/bridge.py`，落日志：`trigger`、`classifier_confidence`、输入快照；
  - 方向分类器用**可训练模型**（LogReg/XGB）+ **概率校准**（Isotonic/Platt），并做样本外 ROC/AUC。

### 1.6 执行层（execution/\*）— **等级：2.5/4（完成度 63%）**

- **现状**：`switch_policy.yaml` 在位；实盘路由未触及（合理）。
- **建议**：
  - 增加**观测面板**：方向误判率、翻转率、滞后分布；
  - 灰度策略：基于 `switch_policy` 的 canary 配额与回滚脚本。

### 1.7 验证层（validation/\*）— **等级：2/4（完成度 50%）**

- **现状**：`directional_breakdown()` 为占位；`validator_v2.yaml` 存在。
- **建议**：
  - 单变量：事件触发 → 方向分层收益/稳定性 → FDR 控制；
  - 多变量：Logit/Probit with TVTP 状态作为协变量 → 稳健 SE；
  - 成本鲁棒：滑点/费率网格与显著性热图；
  - 自动写入 `output/publish_docs/VALIDATION.md`。

### 1.8 输出/文档层（output/\*, README/todo）— **等级：3/4（完成度 75%）**

- **现状**：README/todo 对齐；报告模板在位；
- **建议**：将审计与验证产出由脚本**自动注入**文档，减少手工同步。

---

## 2. 与工程卡片的对照（关键卡片）

| 卡片                      | 期望                                | 现状评估          | 说明/动作                               |
| ----------------------- | --------------------------------- | ------------- | ----------------------------------- |
| **207 宏观慢变量**           | 构建 MA200 等慢变量，入 TVTP 驱动           | **进行中**（占位函数） | 需纳入流水线并做前视泄露检查                      |
| **303 TVTP‑HMM（含宏观驱动）** | TVTP 训练、显著性与样本外对比                 | **未完成**       | 实现 EM + FB(TVTP) + 多起点；落地 artifacts |
| **305 状态推断接口**          | `predict_proba → state, P(Si→Sj)` | **占位**        | 改为加载真实制品；提供批量/流式接口                  |
| **607 AB 热切换**          | PSI/KS/ECE 门控 + 发布绑定              | **规则在位**      | 增加 switch 审计与回放脚本                   |
| **607‑B 方向性判断器**        | 训练化分类器 + 置信校准                     | **占位**        | 采样/特征集/校准/阈值学习；对接日志                 |
| **401 单变量 / 406 汇总**    | 方向分层 + 宏观对比                       | **占位**        | 指标化产出 + FDR；写入 VALIDATION.md        |
| **865 RULES/SCHEMA 扩展** | 触发/字段齐备 + CI 校验                   | **部分完成**      | 加 CI gate + schema 校验脚本             |

---

## 3. 后续 2–4 周落地计划（优先级从高到低）

### P0（基础代价最低、拉动最大）

1. **Data 基建**（3–5 天）
   - `data/ingestion/binance_ohlcv.py`、`data/ingestion/atas_tick_to_1m.py`；
   - `data/manifests/manifest.jsonl` 与 `watermark/`；
   - 单测 + 小规模样本回归。
2. **Microflow 库**（3–4 天）
   - `mfi.py`、`cvd.py`、`imbalance.py`，统一签名与对齐规则；
   - 产出 `featureset.parquet`。

### P1（模型可用化）

3. **TVTP‑HMM 训练（简化版）**（5–7 天）
   - EM(FB with TVTP) + drivers=[MFI,CVD,MA200\_ratio]；
   - 多起点 + 样本外稳定性；
   - `artifacts/model_artifact.json` 落地。
4. **Directional 训练化 + 校准**（3–4 天）
   - LogReg/XGB + Isotonic/Platt；
   - 指标：AUC、精确‑召回、翻转率。

### P2（验证/门禁/执行观测）

5. **Validator 流水化**（3 天）
   - 单变量/多变量输出方向分层 + 宏观对比 → 写入 `VALIDATION.md`；
6. **CI 门禁与执行观测**（2 天）
   - schema 校验 + audit 通过才允 PR；
   - 方向误判率面板与 `switch_audit` 检查。

---

## 4. 风险与缓解

- **数据漂移**：加入 PSI/KS/ECE 日志与门控，启用 `switch_policy` 回滚；
- **过拟合**：TVTP 驱动做降维/正则；多起点 + 时间切片交叉验证；
- **执行一致性**：统一特征/模型签名与版本；打包四键签名并在决策日志中存证。

---

## 5. 关于 `tools/` 的定位

- **长期保留**：这是**治理审计工具链**，应保留为根目录一等公民；
- **不并入 governance/**：治理层放“契约”，`tools/` 放“执行脚本”，分层职责明确；
- **可镜像门槛**：在 `governance/CONTROL_audit.yaml` 镜像最小通过标准，CI 调用 `tools/` 执行审计。


---

## 源文件：docs/工程日志_order_flow_v​_6_（_2025_10_15_）.md

# 工程日志 — OrderFlow V6（2025-10-15）

> 本日志汇总截至 2025-10-15 的项目管理上下文、阶段进展、数据现状与方法、合并与校准方案，以及对 `orderflowv​6_todo_v1.1` 的卡片化修订建议（保持原有内容，同时补充对齐文件格式的新增卡片）。

---

## 0) 项目管理 Context（可供 Agent 长期引用）

**项目名**：OrderFlow V6（向 V7 过渡的“双轨渐进”体系）

**核心方法论（简述）**：

* 核心方法论（一句话画像）：以市场微结构/订单流（Order Flow）为核心观测，结合状态空间模型（HMM/TVTP/HSMM）构建“市场结构—状态—执行”三层体系。上层用Validator v2约束可证伪性（单/多变量显著性 + 成本鲁棒 + 漂移监控），下层以AB 双源热切换管理从低/中频观测到高频状态源的升级。
* 当前现状：我们已完成 000–108 的工程卡片并在本地跑通最小闭环；ATAS 自定义 indicator 成功导出 JSON（Bar/Tick），Binance OHLCV 历史数据已就绪做低/中频观测。经过对“3 个月聚合 Bar vs 7 天真 Tick vs 1 天 L2”的数据精度/窗口讨论，最终确定Plan A（双轨渐进）：以 Binance 低/中频轨尽快形成可解释的状态机与验证闭环，同时连续滚动积累 ATAS Tick/L2，在“重叠窗”内完成 minute↔tick 的映射与校准，再以成本鲁棒与执行可达性为闸门，切换到高频状态源。
* 工程采用 **双轨渐进** 处理数据，以训练验证市场结构和状态的HMM/TVTP/HSMM模型：

  * **轨道 A（低/中频｜Binance 主）**：

    1. **A1 数据摄取**：Binance OHLCV（1m/可选 1s）+ aggTrades 历史包标准化（统一 bar 边界/时区）。
    2. **A2 特征工程**：minute 级聚合微结构影子（聚合版 CVD/主动量）、价量波动分位、VWAP 偏离、ATR 等；固化 *feature schema* 与版本。
    3. **A3 状态建模**：HMM/TVTP-HMM（把波动/失衡作 Z_t）形成“可解释状态机”（趋势/盘整/转场），仅做**观测与解释**，不承诺可交易性。
    4. **A4 验证闭环**：Validator v2（单/多变量显著性、**成本鲁棒 base/+50%/×2**、漂移监控）；形成 `state_report.md`。
    5. **A5 基线接入**：把轨 A 的状态接入执行层作为**基线状态源**，用于 AB 对照与后续热切换的回滚锚点。
  * **轨道 B（高频｜ATAS 主）**：

    1. **B1 连续抓取**：ATAS Tick（7 天滚动）+ 备用 L2（≈1 天）；日级归档（JSON→Parquet）、质量报表（笔数/缺口）。
    2. **B2 高频特征**：逐笔 CVD、订单不平衡、吸收/冰山、DOM 队列压力、冲击近似与成交流量；固化事件抽取规则。
    3. **B3 重叠窗校准**（≥7×24h）：

       * **映射**：Tick→minute 的同名特征做均值/方差对齐与漂移监控（PSI/KS），输出 `mapping_tick2bar.pkl`；
       * **置信度校准**：对状态概率做温度缩放/等值回归，输出 `calibration_profile.json`；
       * **停留分布**：若差异显著，采用 **HSMM** 设置最小驻留与黏性，降低抖动与伪切换。
    4. **B4 闸门检查**：

       * **可执行性**：简化排队成交率与冲击惩罚评估；
       * **成本鲁棒**：base/+50%/×2 三档均为正；
       * **分布健康**：关键特征漂移在阈值内；全部达标方可进入候选状态源。
    5. **B5 热切换**：执行层 **AB 双源热切换**——当 B 达标即切主；若退化/告警则自动回滚至 A；全程留存切换与回滚审计日志。
  * **节拍与产物**：每两周形成 `merge_and_calibration_report.md` 与 `validator_report.md`；数据与模型资产采用固定落盘路径与版本号（manifest），确保可复用与可追溯。

**Plan A / Plan B 定义与取舍**：

* **Plan A（双轨渐进）**：以 **Binance 低/中频**先跑起观测与验证闭环（轨 A），**同时**滚动积累 **ATAS Tick/L2**（轨 B）。在**重叠窗**完成 **minute↔tick 映射**、**置信度标定**、**停留分布校准（必要时 HSMM 黏性）**。当候选高频状态机通过**可执行性 + 成本鲁棒 + 分布健康**三道闸门后，以 **AB 双源热切换**替换执行层状态源。
* **Plan B（低频先行）**：放弃中频与微结构阶段性目标，专注低/中低频（7–20 天节奏）建模与验证，以快速产出“可解释曲线”；后续待高频数据积累充足，再整体迁回中频/高频。
* **为何选择 Plan A**：我们的“核心资产”是 **可迁移的系统 + 数据 + 校准器**（而非一时的模型或低频显著曲线）。Plan A 能持续沉淀跨粒度的映射与校准能力，统一验证口径，降低未来替换状态源的结构性成本；同时通过 **AB 双源热切换**管理升级/回滚风险。Plan B 虽然出结果快，但易形成“慢世界真理”，在切回中高频时重构成本高且存在先验偏置风险。

**当前现状（概况）**：

* 000–108 卡片工程化完成并本地可运行；
* ATAS 自定义 Indicator 可导出 JSON（Bar/Tick）；
* 已拉取 Binance OHLCV 历史作为低/中频观测地基；
* 明确了 ATAS 数据窗口与精度限制（Bar≤3 个月、Tick≤7 天、L2≈1 天），以及 Binance 历史包长期回溯的优势；
* 经讨论后确定 **Plan A（双轨渐进）** 为主线。

**项目最核心资产（必须持续沉淀/复用）**：

1. **可迁移的研究与验证系统**（数据→特征/标签→状态→验证→执行），尤其是 **Validator v2** 的统一口径与报告；
2. **数据与特征资产**（Binance 低/中频 + ATAS Tick/L2 的原始/衍生特征），以及跨粒度的 **对齐/校准器**（minute↔tick 映射、置信度标定、停留分布/HSMM 参数）；
3. **执行层 AB 双源热切换机制**（可控升级/可回滚）。

**阶段里程碑（“已完成”的事实）**：

* **A｜工程落地**：000–108 卡片在本地完成并跑通最小闭环（导出→落地→基础校验）。
* **B｜数据认知**：验证 ATAS 三种精度与时间窗口；确认 Binance 历史包可作为低/中频主干与回补来源。
* **C｜路线决策**：拍板 **Plan A**；确定后续围绕“重叠窗校准 + 成本鲁棒 + 热切换”的节奏推进。

**风险与选择理由**：

* **为何选 Plan A**：我们的“核心资产定义”是 **系统 + 数据 + 校准器**，而非一次性的模型或低频曲线。Plan A 能沉淀跨粒度的可复用能力（映射/校准/统一验证），降低未来替换状态源的成本与风险。
* **慢世界真理的误导**（认知风险）：低/中低频显著性常在微结构/执行层失效；若以低频单线推进，容易固化错误先验，迁移时成本陡增。
* **数据落差的双重风险**：

  1. **实现效果**：粒度/口径差引发系统性偏置，若无校准，低频 posterior 迁往高频易劣化；
  2. **工程复杂度**：双源合并、映射/校准、漂移监控、可执行性预检会提高 Task 难度与时间跨度（需要分区存储、重叠窗、版本化 manifest 与日报体系）。

**度量（项目“核心关注面板”）**：

| 关注维度    | 指标/度量            | 说明                         | 模块归属         | 重要性 |
| ------- | ---------------- | -------------------------- | ------------ | --- |
| 代码稳定性   | 重复错误闭环率          | 同类报错修复后 2 周内复发率            | 工程/基础设施      | 高   |
| 代码稳定性   | CI/本地自检通过率       | lint/单测/数据 schema 自检一次通过占比 | 工程/基础设施      | 中   |
| 数据质量    | 切片连续性/缺失率        | ATAS JSON 连续性、缺失分钟占比       | 数据获取         | 高   |
| 数据质量    | 时间对齐一致率          | Binance vs ATAS bar 边界一致率  | 数据合并/对齐      | 高   |
| 映射与校准   | 特征分布漂移（PSI/KS）   | 同名特征（Binance↔ATAS）在重叠窗的漂移  | 映射/校准        | 高   |
| 映射与校准   | 置信度校准（ECE/Brier） | 状态概率的校准质量                  | 映射/校准/状态     | 高   |
| 映射与校准   | 停留分布差异           | 状态持久性分布 KS/黏性对比            | 状态/校准        | 中高  |
| 验证/可交易性 | 成本鲁棒通过率          | base/+50%/×2 三档为正的比率       | Validator v2 | 高   |
| 验证/可交易性 | 事件可执行性           | 事件窗内可成交率与冲击近似              | 执行/评估        | 高   |
| 系统稳定性   | 数据管线端到端延迟        | 导出→落地→合并→特征 的延迟            | 流水线          | 中   |
| 系统稳定性   | 存储/IO 压力         | 日增量、压缩比、读写耗时               | 基础设施         | 中   |
| 文档/复用   | 报告完备度            | “合并与校准报告/验证报告”完整性          | 文档/治理        | 中   |

---

## 1) 目前进度（展开）

* **工程化（000–108）**：自定义 ATAS Indicator 在本地成功运行；导出策略包含 `latest.json + 切片`；基础校验通过。
* **数据拉通**：完成 ATAS Bar/Tick 测试导出；Binance OHLCV 历史数据已就绪。`aggTrades` 聚合进入计划。
* **尚未完成**：三源数据的**统一合并**与**持续增量更新**（分区/manifest/日报）尚未落地。
* **方法路线**：

  * **Plan A（双轨渐进）** = 低/中频（Binance）先跑闭环 + 高频（ATAS）滚动累积；
  * 在**重叠窗**完成 minute↔tick 映射、置信度与停留分布校准（必要时 HSMM 黏性）；
  * 通过 **成本鲁棒**与**可执行性**闸门后，以 **AB 双源热切换**把执行层状态源升级。
  * **选择理由**：保障工程进度与长期复用性兼得，避免“慢世界真理”锁死结构。

---

## 2) 情况说明（数据处理与获取的现状）

### 数据来源与角色

| 数据源                                  | 精度/窗口         | 选择理由               | 在项目中的作用                            | 重要程度(1–5) | 应用时序优先级(1–5) |
| ------------------------------------ | ------------- | ------------------ | ---------------------------------- | --------: | -----------: |
| ATAS Bar 聚合（1m/5m/秒/100–1000tick 聚合） | 非真 tick；≤3 个月 | 轻量稳定、与 ATAS 指标口径一致 | 观测层；与 Binance bar 对齐；早期验证 AMT 聚合特征 |         3 |            4 |
| ATAS 真 Tick                          | 真逐笔；≈7 天滚动    | 微结构“金标准”           | 高频状态机主源；为聚合因子提供真值校准                |         5 |            3 |
| ATAS L2（DOM/盘口队列）                    | ≈1 天          | 队列/冲击研究关键          | 执行可达性、冲击近似的高价值特征（后置启用）             |         4 |            2 |
| Binance OHLCV（1m/可选 1s）              | 长回溯；免费        | 低/中频主干；口径稳定        | 先跑闭环的地基；与 ATAS bar 对齐              |         4 |            5 |
| Binance aggTrades（逐笔聚合）              | 长回溯；免费        | 逐笔的轻量替代            | 低/中频轨补“微结构影子”，支撑映射/校准              |         4 |            4 |

### 技术要点（明确定义与动机）

* **双轨数据管线**：

  * 轨 A（低/中频）：Binance OHLCV + aggTrades → minute 特征（CVD（聚合）、VWAP 偏离、ATR、波动/量能分位）→ HMM/TVTP → Validator v2。
  * 轨 B（高频）：ATAS Tick/L2 → 逐笔/盘口特征 → 在**重叠窗**对齐/校准 → 通过闸门后替换状态源。
  * **动机**：让系统先活起来，同时沉淀跨粒度的映射/校准资产，为未来切换做准备。

* **重叠窗校准**：

  * 在两个数据源同时可用的时间段（≥ 7×24h）上完成：

    1. **minute↔tick 特征映射**与分布对齐（均值/方差，PSI/KS 监控）；
    2. **置信度标定**（温度缩放/等值回归）使状态概率可比；
    3. **停留分布校准**（若差异显著，用 **HSMM** 设最小驻留与黏性）。
  * **动机**：解决“慢世界显著—快世界执行落差”的结构错位。

* **AB 双源热切换**：

  * 执行层同时接入两套状态源（低/中频基线；高频候选），当候选源在**校准/鲁棒/可执行性**达标后切主；若退化则回滚到基线。
  * **动机**：降低升级风险，保证执行层的连续性与可追溯性。

---

## 3) 三类数据的获取方法（步骤 + 背后理由）

### A. 3 个月 ATAS Bar 聚合数据

1. **设置图表与时间段（≤3 个月）**：避免越窗导致导出空洞。→ *确保连续性*
2. **选择统一分辨率（1m/5m/秒/聚合tick）**：与项目 bar 边界/时区规范一致。→ *为跨源对齐做准备*
3. **加载导出型 Indicator**：在参数中勾选 POC/VAH/VAL/CVD 等字段。→ *字段集合可版本化，可复现*
4. **配置导出策略（latest + 切片）**：每 bar close 写切片，`latest.json` 提供实时快照。→ *便于增量消费与回放*
5. **导出 & 完整性校验**：生成连续性报告（缺失/重复/跳变）。→ *作为合并准入门槛*
6. **归档与元数据**：`symbol/resolution/date` 分区与字段摘要。→ *支持重算与审计*

### B. 7 天 ATAS 真 Tick

1. **连接真 Tick 数据源**：确认供应质量与逐笔完整性。→ *微结构真相可靠*
2. **Indicator 切换为 Tick 导出**：逐笔字段（价/量/方向/统计钩子）并控制 IO 频率。→ *平衡精度与资源*
3. **滚动窗口管理（7 天）**：保持近窗完整，超窗日打包（JSON→Parquet）。→ *既可训练也控存储*
4. **资源与压缩策略**：高 IOPS 目录、及时压缩与分区。→ *降低合并时 IO 压力*
5. **质量报表**：分钟笔数/零成交分钟/缺口监控与补抓。→ *即时发现断点*

### C. Binance 历史聚合（OHLCV + aggTrades→本地 CVD）

1. **范围与分区策略**：按月/日历史包批量下载。→ *绕开 REST 限速，保证完整性*
2. **OHLCV 落地**：统一 bar 边界/时区；作为低/中频主干。→ *对齐 ATAS Bar 的时间框*
3. **aggTrades 聚合与本地 CVD**：分钟聚合主动/被动买卖量并给出 CVD（聚合版）。→ *补“微结构影子”*
4. **一致性核验（与 ATAS Bar）**：对比均值/方差/极值/缺口并记录偏差。→ *形成映射/校准基线*
5. **持久化与元数据**：Parquet 分区与统计摘要。→ *便于后续自动化消费*

#### 三类数据：获取方法 & 理由对比表

| 类别                          | 获取方法要点                                        | 获取理由（动机）                                    |
| --------------------------- | --------------------------------------------- | ------------------------------------------- |
| ATAS Bar（≤3 个月）             | 统一分辨率；Indicator 字段版本化；latest+切片；连续性自检；分区归档    | 轻量稳定、与 ATAS 指标口径一致；快速形成观测层并与 Binance bar 对齐 |
| ATAS Tick（≈7 天）             | 真逐笔导出；滚动 7 天；高 IOPS 与压缩；质量报表与补抓               | 微结构真相；为校准与高频状态训练提供“金标准”                     |
| Binance 历史（OHLCV+aggTrades） | 历史包批量下载；分钟聚合主动量/CVD；与 ATAS Bar 对比；Parquet+元数据 | 长回溯、免费；低/中频主干；补微结构影子，支撑映射/校准与先跑闭环           |

---

## 4) 三类数据的合并方法（步骤 + 背后理由）

1. **统一时区与 bar 边界**：固定 UTC 与 bar close 规则（右闭左开）。→ *时间是主键，先钉死语义*
2. **建立“对齐索引表”**：以分钟粒度记录可用源、缺失掩码、质量标记。→ *声明式合并，降低脚本分散*
3. **minute↔tick 特征映射（重叠窗）**：从 Tick 聚合 minute 特征，与 Binance/ATAS Bar 同名因子做均值/方差校准；监控 PSI/KS 并标注不可合并段。→ *消解口径差，形成映射器*
4. **置信度/状态校准（重叠窗）**：温度缩放/等值回归校准状态概率；停留分布对比，不一致则切换 HSMM 并设置最小驻留。→ *把状态放回可比较空间*
5. **标签与事件对齐**：统一标签定义（未来 N 分钟收益/波动/突破），重叠窗内确保一致并记录偏差。→ *验证口径统一*
6. **来源优先级/降级策略**：ATAS Tick 聚合 > ATAS Bar > Binance 聚合；降级段写入元数据（来源/校准版本/原因）。→ *合并要可解释可追溯*
7. **成本鲁棒与可执行性预检**：在合并后特征上做简化执行评估（排队率/冲击近似），仅通过三档成本者进入 Validator v2。→ *把“可交易性”前置，减少后段返工*
8. **产物与报告**：

   * 数据产物：`features_lowfreq.parquet`、`features_hft.parquet`；模型资产：`mapping_tick2bar.pkl`、`calibration_profile.json`；
   * 报告：`merge_and_calibration_report.md`（一致率/漂移/残差/降级段与原因）。→ *标准化命名，便于自动化与审计*

---

## 5) 关于 `orderflowv​6_todo_v1.1`：是否需要修改工程卡片？

**结论**：需要。保持原有内容不动，同时按现有文件格式新增/细化卡片，使数据获取（三源分卡）、数据合并（独立大模块）、运行治理（AB 热切换/日报/成本鲁棒）更清晰、可验收。

> **对齐文件格式的新增/修订卡片（示例草案）**
> 字段遵循：`模块｜标题｜目标｜输入｜输出｜关键步骤｜DoD（验收）｜负责人｜优先级｜依赖｜工时估算｜风险&缓解｜落盘路径｜QA/工具`

### 【新增】卡片 111（数据）— ATAS Bar 聚合获取（3 个月）

* **目标**：规范化导出流程（分辨率/字段/切片与 latest 并存/连续性自检/分区归档）。
* **输入**：ATAS 回放/历史；导出 Indicator 配置。
* **输出**：`data/raw/atas/bar/{symbol}/resolution={X}/date=YYYY-MM-DD/*.json`、`export_manifest.json`。
* **关键步骤**：

  1. 设定时间窗与分辨率；
  2. Indicator 字段版本化；
  3. 切片+latest 导出；
  4. 连续性自检并出报告；
  5. 分区与元数据写入（schema、字段摘要）。
* **DoD**：任意 3 天分区缺失率 <0.1%，schema 校验通过；manifest 完整。
* **负责人**：数据工程｜**优先级**：P0｜**依赖**：101,103｜**工时**：M｜**落盘**：`data/raw/atas/bar`。

### 【新增】卡片 112（数据）— ATAS 真 Tick 连续抓取（7 天滚动）

* **目标**：建立真逐笔滚动抓取与归档机制，保证近窗完整，超窗日打包压缩。
* **输入**：ATAS 实时/回放源；Tick 导出参数。
* **输出**：`data/raw/atas/tick/{symbol}/date=YYYY-MM-DD/*.json(.parquet)`、`tick_quality_report.md`。
* **关键步骤**：

  1. 逐笔字段清单与 IO 策略；
  2. 7 天滚动窗口与日打包；
  3. 质量报表（分钟笔数/零成交/缺口）与补抓；
  4. 压缩与分区；
  5. manifest 记录水位与版本。
* **DoD**：近 7 天无缺口；质量报表生成；打包与校验通过。
* **负责人**：数据工程｜**优先级**：P0｜**依赖**：101,102,103｜**工时**：M｜**落盘**：`data/raw/atas/tick`。

### 【新增】卡片 113（数据）— Binance 历史：OHLCV + aggTrades（本地 CVD）

* **目标**：以历史包批量拉取，统一 bar 边界/时区；分钟聚合主动量/CVD（聚合版）；与 ATAS Bar 做基础对齐对比。
* **输入**：Binance 历史包；下载清单。
* **输出**：`data/raw/exchange/{symbol}/kline_1m.parquet`、`data/raw/exchange/{symbol}/aggtrades_1m.parquet`、`exchange_manifest.json`。
* **关键步骤**：

  1. 历史包分段下载与去重；
  2. OHLCV 标准化；
  3. aggTrades→分钟聚合主动量/CVD；
  4. 与 ATAS Bar 的均值/方差/极值/缺口对比；
  5. 分区与元数据。
* **DoD**：对齐后缺失率 ≤0.1%；聚合 CVD 稳定；manifest 完整。
* **负责人**：数据工程｜**优先级**：P0｜**依赖**：104,107｜**工时**：M｜**落盘**：`data/raw/exchange`。

### 【新增】卡片 115（数据合并）— 对齐索引表

* **目标**：以分钟为粒度统一主键，记录可用源、缺失掩码、质量标记。
* **输入**：111/112/113 产出；会话日历。
* **输出**：`data/staged/alignment_index.parquet`。
* **关键步骤**：时区与 bar 边界统一；重复/空洞清理；质量字段定义。
* **DoD**：与三源 join 后主键唯一；空洞标注完整。
* **负责人**：数据工程｜**优先级**：P0｜**依赖**：106,107｜**工时**：S。

### 【新增】卡片 116（数据合并）— minute↔tick 映射与分布校准

* **目标**：建立同名特征的均值/方差对齐；监控 PSI/KS 并输出“不可合并段”。
* **输入**：ATAS Tick 聚合 minute；Binance/ATAS Bar 因子。
* **输出**：`mapping_tick2bar.pkl`、`distribution_shift_report.md`。
* **关键步骤**：重叠窗抽取；线性/分位映射；漂移阈值；段落标注。
* **DoD**：重叠窗 PSI 在阈值内；映射残差可控。
* **负责人**：量化研究｜**优先级**：P0｜**依赖**：115｜**工时**：M。

### 【新增】卡片 117（数据合并）— 置信度与停留分布校准（含 HSMM 黏性）

* **目标**：状态概率经温度缩放/等值回归校准；停留分布差异显著时应用 HSMM 最小驻留。
* **输入**：候选状态机输出；重叠窗样本。
* **输出**：`calibration_profile.json`、`staytime_ks_report.md`。
* **关键步骤**：校准集/验证集拆分；参数拟合；阈值与回滚策略。
* **DoD**：ECE/Brier 达标；黏性后抖动降低且滞后可接受。
* **负责人**：量化研究｜**优先级**：P0｜**依赖**：302,116｜**工时**：M。

### 【新增】卡片 118（数据合并）— 标签/事件对齐与来源优先级降级

* **目标**：统一标签定义（未来 N 分钟收益/波动/突破），制定“ATAS Tick > ATAS Bar > Binance”的降级规则并写入元数据。
* **输入**：对齐索引表与三源特征；标签配置。
* **输出**：`data/processed/features_lowfreq.parquet`、`data/processed/features_hft.parquet`、`merge_and_calibration_report.md`。
* **关键步骤**：标签一致性检查；降级段标注；合并后可执行性预检（排队率/冲击近似）。
* **DoD**：通过三档成本预检的样本才进入 Validator；报告完整。
* **负责人**：数据工程/量化｜**优先级**：P0｜**依赖**：115–117,105｜**工时**：M。

### 【新增】卡片 607（执行）— AB 双源热切换

* **目标**：在执行层同时接入低/中频基线与高频候选；达标后切主，退化自动回滚。
* **输入**：`state_inference` 两路输出；监控指标与阈值。
* **输出**：切换/回滚日志、`switch_policy.yaml`。
* **关键步骤**：切换条件（校准/鲁棒/可执行性）；回滚触发；审计记录。
* **DoD**：演练通过；切换与回滚可复现。
* **负责人**：策略开发｜**优先级**：P0｜**依赖**：305,406｜**工时**：S。

### 【新增】卡片 808（监控）— 数据质量与健康度日报

* **目标**：自动生成 `output/qa/qc/date=YYYY-MM-DD/` 报告（连续性、缺失、漂移告警、存储/IO、延迟、报错闭环）。
* **输入**：对齐索引、合并结果、CI 日志。
* **输出**：`data_qc_report.md`、IM 告警。
* **关键步骤**：指标聚合、阈值、静默期与抑制；只推新增失败分区。
* **DoD**：日报稳定；异常可追踪。
* **负责人**：DevOps｜**优先级**：P1｜**依赖**：108,115–118｜**工时**：S。

### 【强化】卡片 405（验证）— 成本敏感性与鲁棒性（刚性门槛）

* **补充说明**：把三档成本的通过线作为**准入闸门**前置到数据合并后第一步的可执行性预检中（与 118 联动），不达标不入 Validator 主流程。

#### 总结：为何这样修改工程卡片

* **资产沉淀**：把“映射/校准/合并/热切换/日报”实体化为卡片与产物，成为跨版本可复用的核心能力；
* **风控前移**：在合并后即做可执行性与成本鲁棒预筛，避免后段返工；
* **可观测/可回滚**：AB 热切换 + 日报让升级可控、异常可见；
* **治理与协作**：统一命名与产物位置，降低沟通成本，便于代理/协作者执行。

---

## 源文件：docs/工程日志_order_flow_v​_6_（_2025_10_17_).md

# 工程日志 · OrderFlow V6 · （2025-10-17）—修订版

> 记录人：QA 团队（林 / 周 / 邵） · 范围：OrderFlow V6 仓库、工程卡片、V6 综合项目说明书（理论强化版）

---

## 前情提要（Context & Outcomes）

**本次对话做了什么**
- **角色确认**：按 *Part 2: prompt_qa_team*，以独立 QA 身份进行结构化审阅与验收，只依据仓库代码、工程卡片与理论说明书三件套。
- **一致性审查**：检查代码与卡片口径（路径/Schema/UTC/offset/容差/分层校准/成本 Gate/签名等），输出一份 **20 项一次性验收闸门核表**。
- **开发改动复核**：审阅开发团队两条 Codex 指令（卡片修改 + 代码修复），逐条加注 QA 意见；随后对更新压缩包进行复验。
- **最终裁定**：在补齐两处 P0 与一处口径澄清后，QA 返回 **【修改方案通过】**。

**本轮对话的定位**
- 仅记录**已完成的讨论与验收结果**；不包含任何未来计划或路线建议，避免影响后续会话的理解与决策。

---

# Output task 1: Executive Summary（高管摘要）

### 讨论与决策的核心要点
- **聚焦工作内容**（本轮收口范围）
  - 以 **Plan‑A 双轨**的最低可验证闭环为准绳，**只验“数据→校准→成本→质量告警→签名与合规→金丝雀演练（草案）”**。
  - 不涉及未来状态机实现与真实热切换，仅验证前置护栏与证据链是否完备。

- **关键决策**
  1) **口径统一**：UTC、右闭左开、`direction=backward` 合并、5–15s 容差、错配率<0.1%（跨分钟就近吸附占比）。
  2) **分层校准**：按波动/量能四分位评估 PSI/KS/ECE；阈值 **PSI<0.2、KS 统计量≤0.1（或 p>0.05，固定其一）、ECE<3%**；越线即不可合并并触发降级。
  3) **成本闸门**：base / +50% / ×2 三档任一档净效应<0 → 阻断；且 base 档 **边际收益 ≥ 1.5× 成本**。
  4) **签名与合规**：所有 Validator 产物写入 `schema_version/build_id/data_manifest_hash/calibration_hash`；CI 检查 `docs/compliance/COMPLIANCE.md` 必备章节关键字。
  5) **切换前置**（仅作为演练口径）：PSI≤0.1、错配率<0.1%、ECE<3%、bar 连续性≥99.9%、成本 Gate 通过。

### 实际产出（Artifacts）
- **工程卡片与文档**
  - `order_flow_v​_6_todo.md`：新增/强化 109/110/111/112/116/117/118/403/404/405/406/607/808 的**产物/门槛/DoD**，并在页末新增 **P0 Gate 顺序**（Schema→连续性→校准→成本→Validator/签名→Switch）。
  - `docs/compliance/COMPLIANCE.md`：用途/保留期/再分发/脱敏四段；CI 含关键字 Gate。
  - `docs/traceability.md`：建立 **卡片→脚本→产物→报告** 的索引链路。
  - `output/report/release.yml`：绑定 `data_manifest_hash + calibration_hash + model_artifact_id`，用于回滚与影子/金丝雀保留。

- **报告与配置**
  - `bar_continuity_report.md`：连续性≥99.9%；不达标时阻断。
  - `tick_quality_report.md`：到达间隔 **CV≤1.5 & p99≤3×median**；不达标时阻断。
  - `merge_and_calibration_report.md`：`[-2,+2]min` offset 评分曲线；错配率定义与统计，<0.1% 达标。
  - `calibration_profile.json`：分层（波动/量能四分位）**PSI/KS/ECE** 三元组与 PASS/FAIL；越线段列表。
  - `third_party/v6_legacy/validation/configs/priority_downgrade.yaml`：越线/缺口→自动降级到 bar 标签并记录日志。
  - `third_party/v6_legacy/validation/configs/costs.yaml`、`third_party/v6_legacy/validation/configs/preregister.yaml`：成本评估与检验预注册。

- **脚本与 Gate**
  - `data/calibration/calibration.py`：分层 Quantile Mapping + 指标计算。
  - `third_party/v6_legacy/validation/src/precheck_costs.py`：base/+50%/×2 三档评估，任一档<0 即退出；打印成本敏感性曲线。
  - `third_party/v6_legacy/validation/src/validate_outputs.py`：检查产物签名四键，一致性失败即拒收。
  - `third_party/v6_legacy/cli/scripts/update_pipeline.ps1`：在 `qc_summary.md` 回填 `seed、data_manifest_hash、exporter_version、schema_signature`。
  - `third_party/v6_legacy/cli/scripts/canary_switch_dryrun.py`：输出演练版 pre/post（收益/滑点/换手/状态持久度）。

- **导出器与 Schema 对齐**
  - `SimplifiedDataExporter.cs` 写出 `window_id/flush_seq` 并声明“分钟右闭左开”。
  - `preprocessing/schemas/atas_schema.json` 同时支持**扁平/嵌套**吸收字段与元字段白名单。

- **单测与 CI**
  - 单测覆盖：offset/容差、双 Schema、分层校准、成本 Gate、分钟边界（right‑closed）。
  - CI：`TZ=UTC`、仅 lint+pytest、含 **cost gate** 与 **signature gate**、合规关键字检查。

### 验收结论（QA Verdict）
- 初次审阅发现两项 P0 与一项口径澄清；开发修正后，**全部门槛达标**。
- QA 发出最终回执：**【修改方案通过】**。

> 注：本摘要仅陈述本轮对话的**讨论要点与实得成果**，不含未来工作规划。

---

# Output task 2: The Chronicle（对话史记）

**Chronicle‑A｜一致性审查**
- 对齐“UTC、右闭左开、direction=backward、5–15s 容差、错配率<0.1%”等口径；统一分层校准阈值；确认降级策略接入。

**Chronicle‑B｜开发改动审阅**
- 审核两条 Codex 指令（卡片侧/代码侧）：在关键处加注 QA 备注（阈值、定义、Gate 顺序、合规模板、签名四键、CI 检查项）。

**Chronicle‑C｜复验与裁定**
- 新压缩包跑核表：17/20 先达标 → 指定两处 P0（切换前置 PSI 过松；CI 缺合规 Gate）与一处 KS 口径澄清 → 修正后重验全过 → 出具“通过”。

**Chronicle‑D｜证据与索引**
- 证据产物：连续性/间隔报告、offset 曲线与错配率、分层校准 JSON、成本 Gate 报告、产物签名检查日志、合规文档关键字检查。
- 索引文件：`docs/traceability.md` 将卡片 ID ↔ 脚本 ↔ 产物 ↔ 报告一一对应，确保复盘时“证据链闭合”。

---

> 本工程日志 **仅记录已完成的讨论与验收**，不含任何未来任务或时间表，确保后续会话的自主规划不受干扰。


---

## 源文件：docs/工程日志_order_flow_v​_6_（_2025_10_23_）.md

# 工程日志 · 2025-10-23

**项目**：OrderFlow V6  
**主题**：ATAS DLL 数据导出与 bar_vpo_* 特征验证  
**作者**：系统记录  

---

## 一、今日进展概况
1. **DLL 版本更新成功**  
   - 新版 `SimplifiedDataExporter v6.2` 已被 ATAS 正确加载；  
   - 输出数据中 `exporter_version = 6.2.0.0`，`schema_version = v6.2` 确认一致。  

2. **Schema 同步**  
   - 新 schema 已包含 `bar_vpo_price/vol/loc/side` 字段并保持可空；  
   - DLL 正常导出 OHLCV 、 CVD 、 Absorption 等时间序列层数据。  

3. **SafeMode 逻辑修正**  
   - SafeMode 关闭后导出稳定，无重复写入或崩溃；  
   - 输出 flush_seq 递增正常，数据连续性良好。  

---

## 二、当前主要问题
1. **bar_vpo_* 始终 null**  
   - 无论 1m、秒级、tick 精度，导出文件中 `bar_vpo_*` 均为空；  
   - 日志显示 `TryGetVolumeAtPrice` 未命中任何价阶容器；  
   - 说明 ATAS 在当前版本或回放模式下**未向自定义指标暴露 Volume-at-Price / Cluster 对象**。

2. **POC / VAH / VAL 同样无法读取**  
   - 与 bar_vpo 问题一致：ATAS 内部这些指标隶属 VPO/TPO profile 体系，不存在单 bar 级别定义。  

3. **缓存与部署效率问题**  
   - ATAS 持续加载旧 DLL （shadow copy 机制）；  
   - 通过改装配名、版本号 + PowerShell 部署脚本后，已找到一劳永逸的清缓存方案，但仍需在后续版本固化流程。  

---

## 三、已确认结论
- **可导出字段**：时间序列层（OHLCV、CVD、Absorption）工作正常。  
- **不可导出字段**：价阶层（POC / VAH / VAL / bar_vpo_*）在 ATAS SDK 接口中不可直接获取。  
- **原因机制**：ATAS 自定义指标 API 仅暴露时间序列级属性；价阶结构需依赖内部 Cluster/Footprint 对象，而这些对象不对指标开放。  

---

## 四、技术推论
- **POC/VAH/VAL 属于 Profile 语义**（VPO/TPO 口径），定义依赖会话或滚动窗口，不是单 bar 属性。  
- **bar_vpo_* 属于 价阶层 microstructure 指标**，在 ATAS 中并无现成接口，无法通过反射访问。  
- 因此，DLL 继续深挖意义不大，建议把价阶层计算移交至 **Python 预处理侧**。  

---

## 五、后续方向（待下阶段讨论）
1. **冻结 DLL 职责**  
   - 仅保留 OHLCV 、 CVD 、 Absorption 、 元信息导出；  
   - 价阶层字段留空，由下游补全。  

2. **价阶层外部重建方案**  
   - 使用交易所 aggTrades 逐笔数据在 Python 侧重建 Volume-at-Price 分布，生成 bar_vpo_*；  
   - 与 ATAS 数据在 merge 阶段重叠校准（PSI/KS/ECE）。  

3. **部署流程固化**  
   - 保留 PowerShell 一键清缓存脚本；  
   - 每次编译自动改装配名与版本号，防止 ATAS 缓存旧 DLL。  

4. **验证计划**  
   - 若后续 ATAS 开放 Footprint 接口，可恢复 bar_vpo_* 实时计算；  
   - 否则长期维持“时间序列层 = DLL 导出，价阶层 = 交易所重建”的分层结构。  

---

**状态小结**  
> 当前 v6.2 DLL 导出稳定但价阶数据缺失；核心问题并非代码逻辑，而是 ATAS API 访问权限限制。  
> 项目进入“价阶层外部重建”方案评估阶段。

---

## 源文件：docs/工程日志_order_flow_v​_6_（_2025_10_24_).MD

# 工程日志 · 2025-10-24

**项目**：OrderFlow V6
**主题**：ATAS DLL bar_vpo_* 导出问题根因诊断与修复
**作者**：系统记录

---

## 一、问题背景回顾（来自 2025-10-23 日志）
- `SimplifiedDataExporter v6.2` 导出数据中 `bar_vpo_price/bar_vpo_vol/bar_vpo_loc/bar_vpo_side` 字段始终为 `null`；
- 先前诊断认为 ATAS SDK 未向自定义指标暴露 Cluster/Footprint 对象或相关属性，导致无法获取单 bar 内的价阶信息（`TryGetVolumeAtPrice` 始终未命中）。

---

## 二、今日进展：根因诊断与修复
1. **假设修正与文档验证**
   - 依据 AI 协作伙伴建议重新审查 ATAS SDK 对 Cluster/Footprint 数据的访问方式；
   - 查阅官方文档（`IndicatorCandle` 参考）与示例代码，确认 SDK 提供 `candle.MaxVolumePriceInfo` 等公共属性以访问单 bar 最大量价阶。

2. **关键发现**
   - v6.2 版本采用的反射（`GetProperty`）尝试访问可能不存在的内部属性（如 `Clusters`、`Footprint`），属于错误数据路径；
   - 正确做法是直接使用 SDK 暴露的公共成员属性。

3. **代码修复（SimplifiedDataExporter v6.3）**
   - **版本升级**：调整 `SimplifiedDataExporter.cs` 与 `.csproj` 中的命名空间、类名、常量、程序集名称和版本号，将所有标识由 v6.2 更新为 v6.3，以强制 ATAS 加载新 DLL 并规避缓存；
   - **逻辑修正**：在 `OnCalculate` 中移除基于反射及 `TryGetVolumeAtPrice` 的 VPO 计算逻辑，改用 `candle.MaxVolumePriceInfo` 直接获取最大量价阶，同时直接访问 `candle.Low`、`candle.High`；
   - **代码清理**：删除失效的 `TryGetVolumeAtPrice`、`SafeConvertToDouble` 辅助函数及 `System.Reflection` 引用；
   - **部署验证**：编译生成 `SimplifiedDataExporter.V63.dll`，部署至 ATAS 指标目录，并在回放/实时数据下验证 `latest.json` 与 `bar_YYYYMMDD.jsonl` 输出。

---

## 三、结果确认
- 导出的 JSON 数据中，`exporter_version = 6.3.0.0`、`schema_version = v6.3`；
- `bar_vpo_price/bar_vpo_vol/bar_vpo_loc/bar_vpo_side` 字段均填充非空值；
- 示例：`"bar_vpo_price": 110490.0, "bar_vpo_vol": 7.853, "bar_vpo_loc": 0.0, "bar_vpo_side": "bear"`。

---

## 四、结论
- 10 月 23 日认为 “ATAS API 访问权限限制” 导致 bar_vpo_* 导出失败的结论不成立；
- 根因在于 v6.2 代码采用错误的数据访问方式（反射猜测内部属性），未直接使用 `candle.MaxVolumePriceInfo` 等公共属性；
- 通过修正访问路径并升级 DLL 后，bar_vpo_* 数据导出功能恢复正常。

---

**状态小结**
> DLL 导出 bar_vpo_* 数据的功能已恢复正常，项目可继续推进下游数据处理与特征工程。
